# 未来的备忘录
这里标识了一些未来打算做的想法的雏形，但由于排期的原因，暂时先在这堆着，防止遗忘
------
* RenderGraph
    * 信息收集方面基于ECS架构，避免避免CacheMiss等问题，同时便于多线程提高效率
    * 提前构建管线过程，将原本的RenderGraph中运行时才发生的任务队列分配及生成的任务提前构建
    * 通过提前构建管线过程，明确整个RenderGraph执行过程中所有需要的资源，并将相应的资源提前创建，避免运行时分配，以及运行时缓存查找等操作
* 低成本的，支持间接光反射和动态光源的全局GI
    * 与现代引擎中的光照探针有一些类似，但将原本的球谐函数衰减至简单的颜色值，同时将会进行间接光反射的物体也简化为一个点，来参与GI
    * 流程上大约是这样
        * 首先由用户在引擎中构建光照体积及密度，构建好后，会根据其密度与体积，来构建出一个Texture3D，理论上也可以用球，胶囊体之类的形状，但用长方体显然更省时
        * 在光照构建过程中，通过离线计算，包括光追等高成本的方式，计算得出穿过光照体积中每个体素的光通量积分，得出一个预计算的颜色（或许还可以搭配球谐之类的来表现更优秀的效果，但球谐是否会导致后续的实时计算复杂化有些说不准）
        * 而后，用户可以在引擎中额外标识间接光反射点，这种间接光反射点一般用于非光源，但有大面积相近颜色的地方，例如一片红布之类的
        * 当渲染实际发生时
            * 将提前烘焙的Texture3D拷贝一份
            * 将各种光源以Texture3D为拷贝出的为RT，以光源所能够影响的范围作为模型，来在Texture3D中完成进一步的渲染，直接将每个体素处所对应的光照流明作为PS输出，叠加到Texture3D上即可
                * 当渲染平行光时，可以以全屏体积（3D全屏片）作为平行光的影响范围，进行绘制
                * 另外可以参照其他的类似延迟渲染的绘制策略，例如所有光源一起穿进去也可以
            * 对每个间接光反射点，根据位置，在Texture3D中插值出自己所在点所对应的光强，颜色，而后以类似于上述光源绘制的方式来进一步将颜色叠加到Texture3D上
            * 如果要做三次光反射，可以重复上述步骤，但感觉最多三次也就差不多了，多了没啥太大必要，本来就低成本的假效果，搞那么多次没啥大用
* 更适应舞台灯光的延迟渲染光源绘制策略
    * 舞台灯光相较于大世界的光源比，一般有着单个光源影响面积小，光源之间存在交叉，影响单个像素的光源数量少的特点
    * 在UE之类的适配于大地形的引擎中，一般会将整个场景以视锥体为核心进行远近，横竖的分块，并针对每一块的光源，以覆盖相应块的屏幕片进行绘制，但这对于舞台类灯光往往可能是不必要的操作
    * 在绘制舞台灯光时，可以根据每个光源所对应的影响体积来构建出一个模型，并且将这个模型在屏幕上渲染，将生成出的颜色绘制到RT上，对于其他的光源所绘制出的颜色也只需要进行相应的叠加即可
    * 另外由于各种光源所对应的模型基本上是固定的，所以在模型构建上基本是没有开销的，可以忽略，而且要是搞得比较严谨的话可以用公告板做进一步优化
* 基于频域空间的水面模拟
    * 首先是背景基础
        1. 水面之类的表面的效果一般都可以表示为若干个波的叠加
        2. 信息存储的精度过低会引发效果失真
        3. 当在远处的水面用不恰当的方式采样了高频波时，会引发闪烁/摩尔纹
        4. 更详尽的信息存储在相对多数的情况下都会带来更优秀的画面
    * 在这样的背景基础下，提出了基于频域空间的水面模拟
        * 首先，在频域空间下，可以将原本储存的波的叠加的信息转化为存储每个波的波幅（在水面波的传播过程中，水面波的频率应该是不会发生太多的变化）
            * 这样的话对于水面上大多数的位置来说，波幅只会发生一个较轻微的变化，甚至可能就是无变化的，例如连续起伏的水浪
            * 对于会快速变化的位置来说，波幅也往往是简单，或者稍微复杂一丢丢的单调变化，即使用线性插值去近似拟合，可能玩家也看不出来
            * 对于一些远处的点，由于部分波频率较高，可能会使得一个像素内直接包含了完整的一个波或更多的波，这时也可以直接对这种高频波进行剔除，或是依赖于这些高频波，来对法线及法线分布进行一个修正
        * 其次是由于在水面上，大多数位置的波幅信息并不需要储存的太精密，所以使得远处的数据可以以一个极低的频率来存储，而岸边的，与角色/其他元素发生交互造成水面波动的位置，可以适当地提高精度，如果将水面信息视为放在一张贴图上，可以将这种操作视为不均匀的UV存储
        * 其次是较为关注的性能计算问题
            * 在这个过程中，我们实际上可以把一个波，包括其导数，以至于高阶导数的数据给放到一个Texture1D贴图里预烘焙出来，例如RGBA通道分别存储波函数本身，波函数的一阶导数，波函数的二阶导数，三阶导数等等，不过一般有个一阶导数来求法线也就差不多了
            * 另外由于上面所描述的频域空间储存信息，所以使得需要存储的水面信息大幅度减小，在这方面的带宽是会降低的
            * 而后是储存波函数的贴图信息，因为是Texture1D，以常规来看，波函数与其一阶导数，以32bitfloat来进行存储，整个波函数上做512个采样点，占用内存也不过4k左右，但以Truning架构为例，其L1缓存有98K，另外由于波函数往往具备一些各种各样的对称性，所以可以对其进行进一步的优化，例如常见的sin函数，可以仅储存其四分之一
        * 但这种水面模拟方式是否会引入其他的问题，或者是相较于现在的水面模拟存在哪些弊端，可能是我暂时没法说清楚的，我对现在的水面模拟方法还没有进行一个非常详尽的调研
* 以三棱锥替代三角面，以构建模型内部信息的建模方式
    * 这个方法最早是来源于物体的破碎，因为物体破碎时会呈现出物体的内部信息，但一般建模的时候只会建模出包围3D物体的一"层"模型，不包含内部信息，所以假设要做实时的随机破碎，常规的模型可能会存在某些问题
    * 如果能获取到物体的内部信息，那么的话对于半透明物体的光追渲染会有着更大的优势，能够进一步表现出物体内部的丰富细节，并且在其中完成与光线的各种交互，例如SSS，水晶玻璃的透射，以至于是一些冰种的玉石的内部的杂质，裂缝的感觉
    * 更进一步的则是对四维物体的渲染
        * 首先是四维空间的物体一定可以被若干个三维的三棱锥将其表面完全包裹住，就类似于一个三维空间中的物体可以被若干个二维的三角面覆盖一样
        * 其次是如果我们选择丢弃掉一个维度，并且将这个维度拍扁，那么的话我们可以将一个空间进行降维，如果我们进行了非线性变化，那么还可以得到透视的效果，这样的话我们就可以从原本的四维空间，得到了一个三维空间
        * 而后我们可以将这个三维空间来完成一个正常的三维渲染，将其中的一个维度进一步拍扁到屏幕上，或者是有趣一点的话还可以搭配VR等方式来进行更有趣的渲染
        * 通过这样的方法，我们可以完成一个对四维空间的绘制，不过在这个过程中，我们可能继续需要完整的重新编写一套渲染管线，这里的渲染管线指的是VSPS那个曾记得渲染管线
* 矢量化建模
    * 背景
        * 这个内容来源于渲染中常见的精度不足/采样频率过高的问题，尤其由于模型虽然可以制作lod模型，但是也无法做到类似贴图的mipmap那样相对全面的lod，而且贴图本身其实在离得近的时候也依旧存在一个精度不足的问题，不管贴图精度多高，总有离得更近的时候
        * 在贴图中，存在矢量图的概念，其借助数学公式来表示图形，而不依赖于传统的像素点，通过这种方式来完成当视角无限拉近的时候，依旧能够清晰地保证图形的精度
    * 在建模过程中，我们可以同样尝试引入矢量化的概念，只不过在原本图片中的像素点，变成了现在的三角形，其实从严谨的角度来说，三角形本身就是矢量的，但是依旧可以套用类似的概念，这里简单理解一下就好
    * 通过将模型矢量化，可以让模型的信息存储变成类似于这样的结构，一个完整的模型的存储上从一组顶点信息，变成了将模型切块后存储的图元组，每一个图元组对应一个相应的函数以拟合出相应的形状，这里的所谓的切块，应该是由美术来自定义的，一般来说，预期的工作流程可能是这样
        * 美术在场景中摆放预定义的图元组，亦或是通过钢笔等工具，来构建自定义的图元组
        * 美术对图元组进行调整
        * 美术增加新的图元组
        * 重复上面的呢若干步骤，直到图元组拼凑出了完整的模型信息
    * 当渲染发生时，我们会经历这样的流程
        * 首先我们用构建好的图元组来替代原本IA阶段传入的VB，并将其作为SRV传入到Shader中
        * 构建AS，在AS中，根据图元组占屏幕空间的比例，图元组的信息差异等信息，将任务分发至MS
        * 在MS中，根据图元组及AS所传递的信息的不同，将一个图元组，多个图元组，亦或是一个不完整的图元组转化为相应的顶点信息，再这个过程中，顶点的疏密度可以直接和距离摄像机距离等相关，以在不影响效率的前提下达到最优的精度
        * 后续的渲染与常规的正常渲染其实就差别不大了，但PS阶段理论上也可以通过获取图元组信息来重建更精密的像素属性，但是由于前述MS阶段可以对顶点进行较密的细分，所以其实直接用插值出来的信息其实也没什么问题
    * 另外如果考虑有着更完善先进的工具链的情况下，其实我们或许可以直接从一个常规的高模中重新拟合出一个以图元组形式构建的模型，并在渲染时以个新的模型进行渲染
    * 这样的话相较于之前的顶点式建模而言，理论上可以有下面几个优点
        * 在相当一部分情况下，可以降低由于传输VB所造成的带宽及显存占用问题
        * 避免了高精度模型在远处的闪烁，以及低精度模型在近处直接暴露出三角面的问题
    * 缺点
        * 如果依赖于美术来建模的话，对美术的工作流调整较大，相当于从PS转AI的难度的升级版
        * 由于模型储存信息及建模方式的改变，可能会使得原本可以美术人工微调，精制的效果变得没那么容易操纵，实际上在现在的AI与PS的比较中，似乎就存在相应的问题，在AI中不是很方便去像PS一样做细节微调
        * 如果依赖于自动从高模构建图元组模型的方法，无法完全确保两边的模型是否真的的确一致，不排除存在若干的潜在问题的可能，不过对待这些诡异的算法，深度学习到是基本上都有一手
        * 整个工作流程高强度的依赖于MeshShader，但这个其实倒也不是什么问题，反正这些东西也不是现在要做在项目里面落地的
